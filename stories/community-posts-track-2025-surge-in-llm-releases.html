<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" type="image/png" href="https://raw.githubusercontent.com/kagisearch/kite-public/main/static/kite-icon.png">
    <link rel="shortcut icon" type="image/png" href="https://raw.githubusercontent.com/kagisearch/kite-public/main/static/kite-icon.png">
    <title>Community posts track 2025 surge in LLM releases - Kite Static</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
            background-color: #fff;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #34495e;
            margin-top: 30px;
            margin-bottom: 15px;
        }
        .category {
            color: #7f8c8d;
            font-size: 0.9em;
            margin-bottom: 10px;
        }
        .summary {
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 4px solid #3498db;
            margin: 20px 0;
        }
        blockquote {
            border-left: 4px solid #3498db;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }
        blockquote cite {
            display: block;
            margin-top: 10px;
            font-size: 0.9em;
            color: #7f8c8d;
        }
        .did-you-know {
            background-color: #fff3cd;
            padding: 15px;
            border-left: 4px solid #ffc107;
            margin: 20px 0;
        }
        ul {
            margin: 15px 0;
            padding-left: 30px;
        }
        li {
            margin: 8px 0;
        }
        .perspective {
            background-color: #f8f9fa;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
        }
        .qna {
            background-color: #e7f3ff;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
        }
        .image {
            margin: 20px 0;
            text-align: center;
        }
        .image img {
            border-radius: 4px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .caption {
            margin-top: 10px;
            font-size: 0.9em;
            color: #666;
            text-align: center;
        }
        .credit {
            font-style: italic;
        }
        .sources {
            margin-top: 30px;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 4px;
        }
        .metadata {
            margin-top: 20px;
            padding: 10px;
            background-color: #f8f9fa;
            font-size: 0.9em;
            color: #666;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .footnote-ref {
            color: #3498db;
            text-decoration: none;
            font-weight: normal;
            font-size: 0.9em;
            vertical-align: super;
            margin-left: 2px;
        }
        .footnote-ref:hover {
            text-decoration: underline;
        }
        .back-link {
            display: inline-block;
            margin-bottom: 20px;
            padding: 8px 16px;
            background-color: #3498db;
            color: white;
            border-radius: 4px;
        }
        .back-link:hover {
            background-color: #2980b9;
            text-decoration: none;
        }
        details {
            margin-top: 30px;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 4px;
            border: 1px solid #ddd;
        }
        summary {
            cursor: pointer;
            font-weight: bold;
            color: #2c3e50;
            padding: 10px;
            user-select: none;
        }
        summary:hover {
            background-color: #e9ecef;
            border-radius: 4px;
        }
        pre {
            background-color: #fff;
            padding: 15px;
            border-radius: 4px;
            overflow-x: auto;
            font-size: 0.85em;
            border: 1px solid #ddd;
        }
        footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #666;
            font-size: 0.9em;
        }
    </style>
</head>
<body>
    <a href="https://rygwdn.github.io/kite-feed/index.html" class="back-link">← Back to Feed</a>
    




<h1>Community posts track 2025 surge in LLM releases</h1>




<p class='category'><strong>Category:</strong> AI</p>







<div class='summary'><p>A community-made infographic and a companion post compile what they describe as a full list of large language models (LLMs) released in 2025, inviting readers to guess the total count and browse the catalog <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a><a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6" class="footnote-ref">[3]</a>. Separately, an article framed as “the year of large models” lays out six high-level takeaways about 2025’s big-model boom <a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF" class="footnote-ref">[2]</a>. Together, the items reflect a notably upbeat, curiosity-driven effort to map a fast-moving AI landscape and make the pace of releases easier to understand for everyday followers <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a><a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF" class="footnote-ref">[2]</a>.</p></div>







<p class="sources"><strong>Primary Source:</strong> <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/">View original article</a></p>












<h2>Key Points</h2><ul>

<li>Infographic focus: One post centers on an infographic that visually summarizes the year’s LLM releases and is shared as a public artifact link for easy viewing <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a>.</li>

<li>Hacker News mirror: The same “full list” artifact is also linked as a discussion item on Hacker News, with the artifact page showing early engagement metrics (2 points, 0 comments at the time captured) <a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6" class="footnote-ref">[3]</a>.</li>

<li>Six takeaways: The 36Kr piece is structured around “6 key insights” positioned as a reflective wrap-up on large-model progress in 2025 <a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF" class="footnote-ref">[2]</a>.</li>

</ul>




<h2>Perspectives</h2>


<div class='perspective'><p>Reddit community poster: Presents the year’s releases via a shareable infographic and invites others to guess the total number of 2025 LLM launches.</p>

<p><strong>Sources:</strong>


<a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/">reddit.com</a>


</p>

</div>



<div class='perspective'><p>36Kr (via Google News): Frames 2025 as “the year of large models,” summarizing developments into six headline insights.</p>

<p><strong>Sources:</strong>


<a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF">google.com</a>


</p>

</div>



<div class='perspective'><p>Artifact compiler page: Publishes a “full list” artifact and points readers to a corresponding Hacker News discussion thread.</p>

<p><strong>Sources:</strong>


<a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6">claude.ai</a>


</p>

</div>









<h2>Technical Details</h2><ul>

<li>LLM (large language model): An LLM is a neural network trained on large text datasets to generate and transform language; the sources focus on tracking how many such models were released during 2025 <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a><a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF" class="footnote-ref">[2]</a>.</li>

<li>Model release tracking: The posts use a curated list and infographic format to make a fast-changing release landscape more navigable for readers <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a><a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6" class="footnote-ref">[3]</a>.</li>

</ul>




<h2>Industry Impact</h2><ul>

<li>AI practitioners: A centralized list/infographic can reduce discovery time for developers and evaluators who need to scan what shipped in 2025 before choosing models to test or deploy <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a><a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6" class="footnote-ref">[3]</a>.</li>

<li>AI media literacy: Packaging the year into “six insights” and a visual catalog can make the pace of LLM progress feel more understandable and less overwhelming for general readers <a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF" class="footnote-ref">[2]</a><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a>.</li>

</ul>




<h2>Scientific Significance</h2><ul>

<li>Field snapshot: By compiling and visualizing releases, the community posts function like a “state of the ecosystem” snapshot—useful for comparing momentum and diversity of offerings without requiring readers to follow every individual announcement <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a><a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6" class="footnote-ref">[3]</a>.</li>

<li>Synthesis vs. cataloging: The 36Kr item emphasizes thematic synthesis (“six key insights”), while the infographic/list emphasizes enumeration; taken together, they show two complementary ways AI observers try to learn from rapid model iteration <a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF" class="footnote-ref">[2]</a><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a>.</li>

</ul>










<h2>Q&A</h2>


<div class='qna'><p><strong>Q:</strong> What criteria did the compiler use to decide which 2025 models count as an “LLM release”?</p>

<p><strong>A:</strong> The sources shown here link to the infographic/list but do not spell out inclusion rules in the provided snippets <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a><a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6" class="footnote-ref">[3]</a>.</p>

</div>



<div class='qna'><p><strong>Q:</strong> Does the “six insights” article focus on technical capability, productization, or market dynamics?</p>

<p><strong>A:</strong> The Google News entry indicates the piece is organized as “6 key insights” but the specific categories are not visible in the provided extract <a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF" class="footnote-ref">[2]</a>.</p>

</div>






<h2>Action Items</h2><ul>

<li>Browse the 2025 LLM infographic: Open the public artifact link shared in the Reddit post to view the infographic and explore the compiled entries <a href="https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/" class="footnote-ref">[1]</a>.</li>

<li>Compare viewpoints across formats: Read the “6 key insights” roundup alongside the release list to contrast thematic conclusions with the underlying catalog of models <a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF" class="footnote-ref">[2]</a><a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6" class="footnote-ref">[3]</a>.</li>

</ul>





<p><strong>Additional Sources:</strong></p><ul>




<li><a href="https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6">https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6</a></li>



<li><a href="https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF">https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF</a></li>


</ul>



















<p><strong>Sources:</strong> google.com, claude.ai, reddit.com</p>









<p class='metadata'><strong>Metadata:</strong> Cluster #3, 3 unique domains, 3 articles</p>




    <details>
        <summary>View Full JSON Data</summary>
        <pre><code>{
  "articles": [
    {
      "date": "2025-12-23T16:55:04+00:00",
      "domain": "reddit.com",
      "image": "",
      "image_caption": "",
      "link": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/",
      "title": "LLM models released in 2025. Can you guess how many?"
    },
    {
      "date": "2025-12-23T11:54:41+00:00",
      "domain": "google.com",
      "image": "",
      "image_caption": "",
      "link": "https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF",
      "title": "2025: 6 Key Insights into the Year of Large Models - 36Kr"
    },
    {
      "date": "2025-12-23T14:46:52+00:00",
      "domain": "claude.ai",
      "image": "",
      "image_caption": "",
      "link": "https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6",
      "title": "Full list of LLM models released in 2025. Can you guess how many?"
    }
  ],
  "category": "AI",
  "cluster_number": 3,
  "did_you_know": "",
  "domains": [
    {
      "favicon": "https://kagiproxy.com/img/l9PDFjFlrTGw8CrNzA_LEuJYhFcKdbBGfwgoitVuKWOjB9HtL935N7HDUndwgdeBOkZMK0KeMEBdhnQrk73AUvFY12nGKHbnhP0BoASQRhQ",
      "name": "google.com"
    },
    {
      "favicon": "https://kagiproxy.com/img/XayHM1oCrRe3R4qYLGgqS3vQy884TDnbEyQU-GYy-9Mr9tzTyokOhqKmpUWg-uo0s-vFVanajm23nwRoeIxxToh8lQoKkfZ1Uhty4XzmpQ",
      "name": "claude.ai"
    },
    {
      "favicon": "https://kagiproxy.com/img/gKSHbEecPgEDnib2NdFN2v1QX_3YGCW_AHlLZCYJOK_oWiqDRnUDeKQplawYJ4o0vRUU_cD8oLDaS8gIXZHoKfitmgOlg2HEevQ0Aw7PNVs",
      "name": "reddit.com"
    }
  ],
  "economic_implications": "",
  "emoji": "\ud83d\udcc8",
  "feed_category": "AI",
  "future_outlook": "",
  "geopolitical_context": "",
  "heading_level": 1,
  "historical_background": "",
  "humanitarian_impact": "",
  "industry_impact": [
    "AI practitioners: A centralized list/infographic can reduce discovery time for developers and evaluators who need to scan what shipped in 2025 before choosing models to test or deploy [reddit.com#1][claude.ai#1].",
    "AI media literacy: Packaging the year into \u201csix insights\u201d and a visual catalog can make the pace of LLM progress feel more understandable and less overwhelming for general readers [google.com#1][reddit.com#1]."
  ],
  "international_reactions": [],
  "item_category": "Model Releases",
  "key_players": [],
  "location": "",
  "number_of_titles": 3,
  "perspectives": [
    {
      "sources": [
        {
          "name": "reddit.com",
          "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/"
        }
      ],
      "text": "Reddit community poster: Presents the year\u2019s releases via a shareable infographic and invites others to guess the total number of 2025 LLM launches."
    },
    {
      "sources": [
        {
          "name": "google.com",
          "url": "https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF"
        }
      ],
      "text": "36Kr (via Google News): Frames 2025 as \u201cthe year of large models,\u201d summarizing developments into six headline insights."
    },
    {
      "sources": [
        {
          "name": "claude.ai",
          "url": "https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6"
        }
      ],
      "text": "Artifact compiler page: Publishes a \u201cfull list\u201d artifact and points readers to a corresponding Hacker News discussion thread."
    }
  ],
  "primary_image": null,
  "published": 1766546726,
  "quote": "",
  "quote_attribution": "",
  "quote_author": "",
  "scientific_significance": [
    "Field snapshot: By compiling and visualizing releases, the community posts function like a \u201cstate of the ecosystem\u201d snapshot\u2014useful for comparing momentum and diversity of offerings without requiring readers to follow every individual announcement [reddit.com#1][claude.ai#1].",
    "Synthesis vs. cataloging: The 36Kr item emphasizes thematic synthesis (\u201csix key insights\u201d), while the infographic/list emphasizes enumeration; taken together, they show two complementary ways AI observers try to learn from rapid model iteration [google.com#1][reddit.com#1]."
  ],
  "source_urls": [
    "https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/",
    "https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6",
    "https://news.google.com/atom/articles/CBMiU0FVX3lxTFBXYTVINXkyeWQxSGkzaEhJUnhwY0tIUXJfUXJuWUM3MFNBTC1YU0sxZEllQUZIMzFMNXlYcVY1SXNiQ015Wlg3WEZYRVRabldTTlRF"
  ],
  "suggested_qna": [
    {
      "answer": "The sources shown here link to the infographic/list but do not spell out inclusion rules in the provided snippets [reddit.com#1][claude.ai#1].",
      "question": "What criteria did the compiler use to decide which 2025 models count as an \u201cLLM release\u201d?"
    },
    {
      "answer": "The Google News entry indicates the piece is organized as \u201c6 key insights\u201d but the specific categories are not visible in the provided extract [google.com#1].",
      "question": "Does the \u201csix insights\u201d article focus on technical capability, productization, or market dynamics?"
    }
  ],
  "summary": "A community-made infographic and a companion post compile what they describe as a full list of large language models (LLMs) released in 2025, inviting readers to guess the total count and browse the catalog [reddit.com#1][claude.ai#1]. Separately, an article framed as \u201cthe year of large models\u201d lays out six high-level takeaways about 2025\u2019s big-model boom [google.com#1]. Together, the items reflect a notably upbeat, curiosity-driven effort to map a fast-moving AI landscape and make the pace of releases easier to understand for everyday followers [reddit.com#1][google.com#1].",
  "talking_points": [
    "Infographic focus: One post centers on an infographic that visually summarizes the year\u2019s LLM releases and is shared as a public artifact link for easy viewing [reddit.com#1].",
    "Hacker News mirror: The same \u201cfull list\u201d artifact is also linked as a discussion item on Hacker News, with the artifact page showing early engagement metrics (2 points, 0 comments at the time captured) [claude.ai#1].",
    "Six takeaways: The 36Kr piece is structured around \u201c6 key insights\u201d positioned as a reflective wrap-up on large-model progress in 2025 [google.com#1]."
  ],
  "technical_details": [
    "LLM (large language model): An LLM is a neural network trained on large text datasets to generate and transform language; the sources focus on tracking how many such models were released during 2025 [reddit.com#1][google.com#1].",
    "Model release tracking: The posts use a curated list and infographic format to make a fast-changing release landscape more navigable for readers [reddit.com#1][claude.ai#1]."
  ],
  "timeline": [],
  "title": "Community posts track 2025 surge in LLM releases",
  "unique_domains": 3,
  "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/",
  "user_action_items": [
    "Browse the 2025 LLM infographic: Open the public artifact link shared in the Reddit post to view the infographic and explore the compiled entries [reddit.com#1].",
    "Compare viewpoints across formats: Read the \u201c6 key insights\u201d roundup alongside the release list to contrast thematic conclusions with the underlying catalog of models [google.com#1][claude.ai#1]."
  ]
}</code></pre>
    </details>
    <footer>
        <p>Generated from <a href="https://kite.kagi.com">Kagi Kite</a> data</p>
    </footer>
</body>
</html>